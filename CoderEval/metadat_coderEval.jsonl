{"namespace": "neo4j._codec.hydration.v1.temporal.hydrate_time", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_codec/hydration/v1/temporal.py", "coder_eval_id": "62e60f43d76274f8a4026e28", "signature_position": [66, 66], "body_position": [67, 82], "signature": "def hydrate_time(nanoseconds, tz=None):", "ground_truth": "def hydrate_time(nanoseconds, tz=None):\n    \"\"\" Hydrator for `Time` and `LocalTime` values.\n\n    :param nanoseconds:\n    :param tz:\n    :return: Time\n    \"\"\"\n    from pytz import FixedOffset\n    seconds, nanoseconds = map(int, divmod(nanoseconds, 1000000000))\n    minutes, seconds = map(int, divmod(seconds, 60))\n    hours, minutes = map(int, divmod(minutes, 60))\n    t = Time(hours, minutes, seconds, nanoseconds)\n    if tz is None:\n        return t\n    tz_offset_minutes, tz_offset_seconds = divmod(tz, 60)\n    zone = FixedOffset(tz_offset_minutes)\n    return zone.localize(t)", "requirement": {"Functionality": "Hydrator for `Time` and `LocalTime` values.\n\n:param nanoseconds:\n:param tz:\n:return: Time", "Arguments": ""}}
{"namespace": "neo4j._codec.hydration.v1.temporal.dehydrate_timedelta", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_codec/hydration/v1/temporal.py", "coder_eval_id": "62e60f3bd76274f8a4026e10", "signature_position": [196, 196], "body_position": [197, 207], "signature": "def dehydrate_timedelta(value):", "ground_truth": "def dehydrate_timedelta(value):\n    \"\"\" Dehydrator for `timedelta` values.\n\n    :param value:\n    :type value: timedelta\n    :return:\n    \"\"\"\n    months = 0\n    days = value.days\n    seconds = value.seconds\n    nanoseconds = 1000 * value.microseconds\n    return Structure(b\"E\", months, days, seconds, nanoseconds)", "requirement": {"Functionality": "Dehydrator for `timedelta` values.\n\n:param value:\n:type value: timedelta\n:return:", "Arguments": ""}}
{"namespace": "neo4j._codec.hydration.v1.temporal.dehydrate_time", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_codec/hydration/v1/temporal.py", "coder_eval_id": "62e60f37d76274f8a4026dfd", "signature_position": [85, 85], "body_position": [86, 103], "signature": "def dehydrate_time(value):", "ground_truth": "def dehydrate_time(value):\n    \"\"\" Dehydrator for `time` values.\n\n    :param value:\n    :type value: Time\n    :return:\n    \"\"\"\n    if isinstance(value, Time):\n        nanoseconds = value.ticks\n    elif isinstance(value, time):\n        nanoseconds = (3600000000000 * value.hour + 60000000000 * value.minute +\n                       1000000000 * value.second + 1000 * value.microsecond)\n    else:\n        raise TypeError(\"Value must be a neo4j.time.Time or a datetime.time\")\n    if value.tzinfo:\n        return Structure(b\"T\", nanoseconds,\n                         int(value.tzinfo.utcoffset(value).total_seconds()))\n    else:\n        return Structure(b\"t\", nanoseconds)", "requirement": {"Functionality": "Dehydrator for `time` values.\n\n:param value:\n:type value: Time\n:return:", "Arguments": ""}}
{"namespace": "neo4j._codec.hydration.v1.spatial.dehydrate_point", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_codec/hydration/v1/spatial.py", "coder_eval_id": "62e60f33d76274f8a4026de9", "signature_position": [44, 44], "body_position": [45, 57], "signature": "def dehydrate_point(value):", "ground_truth": "def dehydrate_point(value):\n    \"\"\" Dehydrator for Point data.\n\n    :param value:\n    :type value: Point\n    :return:\n    \"\"\"\n    dim = len(value)\n    if dim == 2:\n        return Structure(b\"X\", value.srid, *value)\n    elif dim == 3:\n        return Structure(b\"Y\", value.srid, *value)\n    else:\n        raise ValueError(\"Cannot dehydrate Point with %d dimensions\" % dim)", "requirement": {"Functionality": "Dehydrator for Point data.\n\n:param value:\n:type value: Point\n:return:", "Arguments": ""}}
{"namespace": "neo4j._data.keys", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_data.py", "coder_eval_id": "62e60ed4d76274f8a4026da0", "signature_position": [184, 184], "body_position": [185, 189], "signature": "def keys(self):", "ground_truth": "    def keys(self):\n        \"\"\" Return the keys of the record.\n\n        :return: list of key names\n        \"\"\"\n        return list(self.__keys)", "requirement": {"Functionality": "Return the keys of the record.\n\n:return: list of key names", "Arguments": ""}}
{"namespace": "neo4j._sync.io._bolt.protocol_handlers", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_sync/io/_bolt.py", "coder_eval_id": "62e60ecfd76274f8a4026d6a", "signature_position": [180, 180], "body_position": [181, 223], "signature": "@classmethod\ndef protocol_handlers(cls, protocol_version=None):", "ground_truth": "    @classmethod\n    def protocol_handlers(cls, protocol_version=None):\n        \"\"\" Return a dictionary of available Bolt protocol handlers,\n        keyed by version tuple. If an explicit protocol version is\n        provided, the dictionary will contain either zero or one items,\n        depending on whether that version is supported. If no protocol\n        version is provided, all available versions will be returned.\n\n        :param protocol_version: tuple identifying a specific protocol\n            version (e.g. (3, 5)) or None\n        :return: dictionary of version tuple to handler class for all\n            relevant and supported protocol versions\n        :raise TypeError: if protocol version is not passed in a tuple\n        \"\"\"\n\n        # Carry out Bolt subclass imports locally to avoid circular dependency issues.\n        from ._bolt3 import Bolt3\n        from ._bolt4 import (\n            Bolt4x1,\n            Bolt4x2,\n            Bolt4x3,\n            Bolt4x4,\n        )\n        from ._bolt5 import Bolt5x0\n\n        handlers = {\n            Bolt3.PROTOCOL_VERSION: Bolt3,\n            # 4.0 unsupported because no space left in the handshake\n            Bolt4x1.PROTOCOL_VERSION: Bolt4x1,\n            Bolt4x2.PROTOCOL_VERSION: Bolt4x2,\n            Bolt4x3.PROTOCOL_VERSION: Bolt4x3,\n            Bolt4x4.PROTOCOL_VERSION: Bolt4x4,\n            Bolt5x0.PROTOCOL_VERSION: Bolt5x0,\n        }\n\n        if protocol_version is None:\n            return handlers\n\n        if not isinstance(protocol_version, tuple):\n            raise TypeError(\"Protocol version must be specified as a tuple\")\n\n        if protocol_version in handlers:\n            return {protocol_version: handlers[protocol_version]}\n\n        return {}", "requirement": {"Functionality": "Return a dictionary of available Bolt protocol handlers,\nkeyed by version tuple. If an explicit protocol version is\nprovided, the dictionary will contain either zero or one items,\ndepending on whether that version is supported. If no protocol\nversion is provided, all available versions will be returned.\n\n:param protocol_version: tuple identifying a specific protocol\n    version (e.g. (3, 5)) or None\n:return: dictionary of version tuple to handler class for all\n    relevant and supported protocol versions\n:raise TypeError: if protocol version is not passed in a tuple", "Arguments": ""}}
{"namespace": "neo4j.work.query.unit_of_work", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/work/query.py", "coder_eval_id": "62e60e49d76274f8a4026d25", "signature_position": [39, 39], "body_position": [40, 79], "signature": "def unit_of_work(metadata=None, timeout=None):", "ground_truth": "def unit_of_work(metadata=None, timeout=None):\n    \"\"\"This function is a decorator for transaction functions that allows extra control over how the transaction is carried out.\n\n    For example, a timeout may be applied::\n\n        from neo4j import unit_of_work\n\n        @unit_of_work(timeout=100)\n        def count_people_tx(tx):\n            result = tx.run(\"MATCH (a:Person) RETURN count(a) AS persons\")\n            record = result.single()\n            return record[\"persons\"]\n\n    :param metadata:\n        a dictionary with metadata.\n        Specified metadata will be attached to the executing transaction and visible in the output of ``dbms.listQueries`` and ``dbms.listTransactions`` procedures.\n        It will also get logged to the ``query.log``.\n        This functionality makes it easier to tag transactions and is equivalent to ``dbms.setTXMetaData`` procedure, see https://neo4j.com/docs/operations-manual/current/reference/procedures/ for procedure reference.\n    :type metadata: dict\n\n    :param timeout:\n        the transaction timeout in seconds.\n        Transactions that execute longer than the configured timeout will be terminated by the database.\n        This functionality allows to limit query/transaction execution time.\n        Specified timeout overrides the default timeout configured in the database using ``dbms.transaction.timeout`` setting.\n        Value should not represent a negative duration.\n        A zero duration will make the transaction execute indefinitely.\n        None will use the default timeout configured in the database.\n    :type timeout: float or :const:`None`\n    \"\"\"\n\n    def wrapper(f):\n\n        def wrapped(*args, **kwargs):\n            return f(*args, **kwargs)\n\n        wrapped.metadata = metadata\n        wrapped.timeout = timeout\n        return wrapped\n\n    return wrapper", "requirement": {"Functionality": "This function is a decorator for transaction functions that allows extra control over how the transaction is carried out.\n\nFor example, a timeout may be applied::\n\n    from neo4j import unit_of_work\n\n    @unit_of_work(timeout=100)\n    def count_people_tx(tx):\n        result = tx.run(\"MATCH (a:Person) RETURN count(a) AS persons\")\n        record = result.single()\n        return record[\"persons\"]\n\n:param metadata:\n    a dictionary with metadata.\n    Specified metadata will be attached to the executing transaction and visible in the output of ``dbms.listQueries`` and ``dbms.listTransactions`` procedures.\n    It will also get logged to the ``query.log``.\n    This functionality makes it easier to tag transactions and is equivalent to ``dbms.setTXMetaData`` procedure, see https://neo4j.com/docs/operations-manual/current/reference/procedures/ for procedure reference.\n:type metadata: dict\n\n:param timeout:\n    the transaction timeout in seconds.\n    Transactions that execute longer than the configured timeout will be terminated by the database.\n    This functionality allows to limit query/transaction execution time.\n    Specified timeout overrides the default timeout configured in the database using ``dbms.transaction.timeout`` setting.\n    Value should not represent a negative duration.\n    A zero duration will make the transaction execute indefinitely.\n    None will use the default timeout configured in the database.\n:type timeout: float or :const:`None`", "Arguments": ""}}
{"namespace": "neo4j._data.index", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_data.py", "coder_eval_id": "62e60e05d76274f8a4026cfd", "signature_position": [149, 149], "body_position": [150, 166], "signature": "def index(self, key):", "ground_truth": "    def index(self, key):\n        \"\"\" Return the index of the given item.\n\n        :param key: a key\n        :return: index\n        :rtype: int\n        \"\"\"\n        if isinstance(key, int):\n            if 0 <= key < len(self.__keys):\n                return key\n            raise IndexError(key)\n        elif isinstance(key, str):\n            try:\n                return self.__keys.index(key)\n            except ValueError:\n                raise KeyError(key)\n        else:\n            raise TypeError(key)", "requirement": {"Functionality": "Return the index of the given item.\n\n:param key: a key\n:return: index\n:rtype: int", "Arguments": ""}}
{"namespace": "neo4j._data.values", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_data.py", "coder_eval_id": "62e60da4d76274f8a4026cf1", "signature_position": [191, 191], "body_position": [192, 210], "signature": "def values(self, *keys):", "ground_truth": "    def values(self, *keys):\n        \"\"\" Return the values of the record, optionally filtering to\n        include only certain values by index or key.\n\n        :param keys: indexes or keys of the items to include; if none\n                     are provided, all values will be included\n        :return: list of values\n        :rtype: list\n        \"\"\"\n        if keys:\n            d = []\n            for key in keys:\n                try:\n                    i = self.index(key)\n                except KeyError:\n                    d.append(None)\n                else:\n                    d.append(self[i])\n            return d\n        return list(self)", "requirement": {"Functionality": "Return the values of the record, optionally filtering to\ninclude only certain values by index or key.\n\n:param keys: indexes or keys of the items to include; if none\n             are provided, all values will be included\n:return: list of values\n:rtype: list", "Arguments": ""}}
{"namespace": "neo4j._data.data", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_data.py", "coder_eval_id": "62e60b10d76274f8a4026ccd", "signature_position": [231, 231], "body_position": [232, 243], "signature": "def data(self, *keys):", "ground_truth": "    def data(self, *keys):\n        \"\"\" Return the keys and values of this record as a dictionary,\n        optionally including only certain values by index or key. Keys\n        provided in the items that are not in the record will be\n        inserted with a value of :const:`None`; indexes provided\n        that are out of bounds will trigger an :exc:`IndexError`.\n\n        :param keys: indexes or keys of the items to include; if none\n                      are provided, all values will be included\n        :return: dictionary of values, keyed by field name\n        :raises: :exc:`IndexError` if an out-of-bounds index is specified\n        \"\"\"\n        return RecordExporter().transform(dict(self.items(*keys)))", "requirement": {"Functionality": "Return the keys and values of this record as a dictionary,\noptionally including only certain values by index or key. Keys\nprovided in the items that are not in the record will be\ninserted with a value of :const:`None`; indexes provided\nthat are out of bounds will trigger an :exc:`IndexError`.\n\n:param keys: indexes or keys of the items to include; if none\n              are provided, all values will be included\n:return: dictionary of values, keyed by field name\n:raises: :exc:`IndexError` if an out-of-bounds index is specified", "Arguments": ""}}
{"namespace": "neo4j._codec.packstream.v1.__init__.pop_u16", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_codec/packstream/v1/__init__.py", "coder_eval_id": "62e6087bd76274f8a4026bfa", "signature_position": [453, 453], "body_position": [454, 462], "signature": "def pop_u16(self):", "ground_truth": "    def pop_u16(self):\n        \"\"\" Remove the last two bytes of data, returning them as a big-endian\n        16-bit unsigned integer.\n        \"\"\"\n        if self.used >= 2:\n            value = 0x100 * self.data[self.used - 2] + self.data[self.used - 1]\n            self.used -= 2\n            return value\n        else:\n            return -1", "requirement": {"Functionality": "Remove the last two bytes of data, returning them as a big-endian\n16-bit unsigned integer.", "Arguments": ""}}
{"namespace": "neo4j._async.io._bolt3.discard", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_async/io/_bolt3.py", "coder_eval_id": "62e6087ad76274f8a4026bf2", "signature_position": [246, 247], "body_position": [249, 252], "signature": "def discard(self, n=-1, qid=-1, dehydration_hooks=None, hydration_hooks=None, **handlers):", "ground_truth": "    def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n        # Just ignore n and qid, it is not supported in the Bolt 3 Protocol.\n        log.debug(\"[#%04X]  C: DISCARD_ALL\", self.local_port)\n        self._append(b\"\\x2F\", (),\n                     Response(self, \"discard\", hydration_hooks, **handlers),\n                     dehydration_hooks=dehydration_hooks)", "requirement": {"Functionality": "Appends a DISCARD message to the output queue.\n\n:param n: number of records to discard, default = -1 (ALL)\n:param qid: query ID to discard for, default = -1 (last query)\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object", "Arguments": ""}}
{"namespace": "neo4j._async.io._bolt3.begin", "type": "class", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_async/io/_bolt3.py", "coder_eval_id": "62e60879d76274f8a4026bec", "signature_position": [262, 264], "body_position": [265, 302], "signature": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None, db=None, imp_user=None, dehydration_hooks=None, hydration_hooks=None, **handlers):", "ground_truth": "    def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n        if db is not None:\n            raise ConfigurationError(\n                \"Database name parameter for selecting database is not \"\n                \"supported in Bolt Protocol {!r}. Database name {!r}.\".format(\n                    self.PROTOCOL_VERSION, db\n                )\n            )\n        if imp_user is not None:\n            raise ConfigurationError(\n                \"Impersonation is not supported in Bolt Protocol {!r}. \"\n                \"Trying to impersonate {!r}.\".format(\n                    self.PROTOCOL_VERSION, imp_user\n                )\n            )\n        extra = {}\n        if mode in (READ_ACCESS, \"r\"):\n            extra[\"mode\"] = \"r\"  # It will default to mode \"w\" if nothing is specified\n        if bookmarks:\n            try:\n                extra[\"bookmarks\"] = list(bookmarks)\n            except TypeError:\n                raise TypeError(\"Bookmarks must be provided within an iterable\")\n        if metadata:\n            try:\n                extra[\"tx_metadata\"] = dict(metadata)\n            except TypeError:\n                raise TypeError(\"Metadata must be coercible to a dict\")\n        if timeout is not None:\n            try:\n                extra[\"tx_timeout\"] = int(1000 * float(timeout))\n            except TypeError:\n                raise TypeError(\"Timeout must be specified as a number of seconds\")\n            if extra[\"tx_timeout\"] < 0:\n                raise ValueError(\"Timeout must be a positive number or 0.\")\n        log.debug(\"[#%04X]  C: BEGIN %r\", self.local_port, extra)\n        self._append(b\"\\x11\", (extra,),\n                     Response(self, \"begin\", hydration_hooks, **handlers),\n                     dehydration_hooks=dehydration_hooks)", "requirement": {"Functionality": "Appends a BEGIN message to the output queue.\n\n:param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n:param bookmarks: iterable of bookmark values after which this transaction should begin\n:param metadata: custom metadata dictionary to attach to the transaction\n:param timeout: timeout for transaction execution (seconds)\n:param db: name of the database against which to begin the transaction\n    Requires Bolt 4.0+.\n:param imp_user: the user to impersonate\n    Requires Bolt 4.4+\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object\n:return: Response object", "Arguments": ""}}
{"namespace": "neo4j.time._arithmetic.round_half_to_even", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/time/_arithmetic.py", "coder_eval_id": "62e60723d76274f8a4026b75", "signature_position": [95, 95], "body_position": [96, 124], "signature": "def round_half_to_even(n):", "ground_truth": "def round_half_to_even(n):\n    \"\"\"\n\n        >>> round_half_to_even(3)\n        3\n        >>> round_half_to_even(3.2)\n        3\n        >>> round_half_to_even(3.5)\n        4\n        >>> round_half_to_even(3.7)\n        4\n        >>> round_half_to_even(4)\n        4\n        >>> round_half_to_even(4.2)\n        4\n        >>> round_half_to_even(4.5)\n        4\n        >>> round_half_to_even(4.7)\n        5\n\n    :param n:\n    :return:\n    \"\"\"\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        up = int(n + 0.5)\n        down = int(n - 0.5)\n        return up if up % 2 == 0 else down\n    else:\n        return int(round(n))", "requirement": {"Functionality": ">>> round_half_to_even(3)\n    3\n    >>> round_half_to_even(3.2)\n    3\n    >>> round_half_to_even(3.5)\n    4\n    >>> round_half_to_even(3.7)\n    4\n    >>> round_half_to_even(4)\n    4\n    >>> round_half_to_even(4.2)\n    4\n    >>> round_half_to_even(4.5)\n    4\n    >>> round_half_to_even(4.7)\n    5\n\n:param n:\n:return:", "Arguments": ""}}
{"namespace": "neo4j._spatial.__init__.point_type", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_spatial/__init__.py", "coder_eval_id": "62e60707d76274f8a4026b69", "signature_position": [70, 70], "body_position": [71, 99], "signature": "def point_type(name, fields, srid_map):", "ground_truth": "def point_type(name, fields, srid_map):\n    \"\"\" Dynamically create a Point subclass.\n    \"\"\"\n\n    def srid(self):\n        try:\n            return srid_map[len(self)]\n        except KeyError:\n            return None\n\n    attributes = {\"srid\": property(srid)}\n\n    for index, subclass_field in enumerate(fields):\n\n        def accessor(self, i=index, f=subclass_field):\n            try:\n                return self[i]\n            except IndexError:\n                raise AttributeError(f)\n\n        for field_alias in {subclass_field, \"xyz\"[index]}:\n            attributes[field_alias] = property(accessor)\n\n    cls = type(name, (Point,), attributes)\n\n    with srid_table_lock:\n        for dim, srid in srid_map.items():\n            srid_table[srid] = (cls, dim)\n\n    return cls", "requirement": {"Functionality": "Dynamically create a Point subclass.", "Arguments": ""}}
{"namespace": "neo4j._meta.deprecated", "type": "function", "project_path": "neo4j/neo4j-python-driver", "completion_path": "neo4j/_meta.py", "coder_eval_id": "62e5dc9ed76274f8a4026b5b", "signature_position": [46, 46], "body_position": [47, 72], "signature": "def deprecated(message):", "ground_truth": "def deprecated(message):\n    \"\"\" Decorator for deprecating functions and methods.\n\n    ::\n\n        @deprecated(\"'foo' has been deprecated in favour of 'bar'\")\n        def foo(x):\n            pass\n\n    \"\"\"\n    def decorator(f):\n        if asyncio.iscoroutinefunction(f):\n            @wraps(f)\n            async def inner(*args, **kwargs):\n                deprecation_warn(message, stack_level=2)\n                return await f(*args, **kwargs)\n\n            return inner\n        else:\n            @wraps(f)\n            def inner(*args, **kwargs):\n                deprecation_warn(message, stack_level=2)\n                return f(*args, **kwargs)\n\n            return inner\n\n    return decorator", "requirement": {"Functionality": "Decorator for deprecating functions and methods.\n\n::\n\n    @deprecated(\"'foo' has been deprecated in favour of 'bar'\")\n    def foo(x):\n        pass", "Arguments": ""}}
{"namespace": "pre_commit.languages.r._inline_r_setup", "type": "function", "project_path": "pre-commit/pre-commit", "completion_path": "pre_commit/languages/r.py", "coder_eval_id": "62e4fc3c85ea98643089041e", "signature_position": [155, 155], "body_position": [156, 164], "signature": "def _inline_r_setup(code: str) -> str:", "ground_truth": "def _inline_r_setup(code: str) -> str:\n    \"\"\"\n    Some behaviour of R cannot be configured via env variables, but can\n    only be configured via R options once R has started. These are set here.\n    \"\"\"\n    with_option = f\"\"\"\\\n    options(install.packages.compile.from.source = \"never\")\n    {code}\n    \"\"\"\n    return with_option", "requirement": {"Functionality": "Some behaviour of R cannot be configured via env variables, but can\nonly be configured via R options once R has started. These are set here.", "Arguments": ""}}
{"namespace": "pre_commit.xargs.xargs", "type": "function", "project_path": "pre-commit/pre-commit", "completion_path": "pre_commit/xargs.py", "coder_eval_id": "62e4fbda85ea986430890405", "signature_position": [116, 124], "body_position": [125, 168], "signature": "def xargs(cmd: tuple[str, ...], varargs: Sequence[str], *, color: bool=False, target_concurrency: int=1, _max_length: int=_get_platform_max_length(), **kwargs: Any) -> tuple[int, bytes]:", "ground_truth": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any,\n) -> tuple[int, bytes]:\n    \"\"\"A simplified implementation of xargs.\n\n    color: Make a pty if on a platform that supports it\n    target_concurrency: Target number of partitions to run concurrently\n    \"\"\"\n    cmd_fn = cmd_output_p if color else cmd_output_b\n    retcode = 0\n    stdout = b''\n\n    try:\n        cmd = parse_shebang.normalize_cmd(cmd)\n    except parse_shebang.ExecutableNotFoundError as e:\n        return e.to_output()[:2]\n\n    # on windows, batch files have a separate length limit than windows itself\n    if (\n            sys.platform == 'win32' and\n            cmd[0].lower().endswith(('.bat', '.cmd'))\n    ):  # pragma: win32 cover\n        # this is implementation details but the command gets translated into\n        # full/path/to/cmd.exe /c *cmd\n        cmd_exe = parse_shebang.find_executable('cmd.exe')\n        # 1024 is additionally subtracted to give headroom for further\n        # expansion inside the batch file\n        _max_length = 8192 - len(cmd_exe) - len(' /c ') - 1024\n\n    partitions = partition(cmd, varargs, target_concurrency, _max_length)\n\n    def run_cmd_partition(\n            run_cmd: tuple[str, ...],\n    ) -> tuple[int, bytes, bytes | None]:\n        return cmd_fn(\n            *run_cmd, retcode=None, stderr=subprocess.STDOUT, **kwargs,\n        )\n\n    threads = min(len(partitions), target_concurrency)\n    with _thread_mapper(threads) as thread_map:\n        results = thread_map(run_cmd_partition, partitions)\n\n        for proc_retcode, proc_out, _ in results:\n            retcode = max(retcode, proc_retcode)\n            stdout += proc_out\n\n    return retcode, stdout", "requirement": {"Functionality": "A simplified implementation of xargs.\n\ncolor: Make a pty if on a platform that supports it\ntarget_concurrency: Target number of partitions to run concurrently", "Arguments": ""}}
{"namespace": "pre_commit.languages.helpers._shuffled", "type": "function", "project_path": "pre-commit/pre-commit", "completion_path": "pre_commit/languages/helpers.py", "coder_eval_id": "62e4fbda85ea986430890403", "signature_position": [114, 114], "body_position": [115, 121], "signature": "def _shuffled(seq: Sequence[str]) -> list[str]:", "ground_truth": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    \"\"\"Deterministically shuffle\"\"\"\n    fixed_random = random.Random()\n    fixed_random.seed(FIXED_RANDOM_SEED, version=1)\n\n    seq = list(seq)\n    fixed_random.shuffle(seq)\n    return seq", "requirement": {"Functionality": "Deterministically shuffle", "Arguments": ""}}
{"namespace": "pre_commit.util.parse_version", "type": "function", "project_path": "pre-commit/pre-commit", "completion_path": "pre_commit/util.py", "coder_eval_id": "62e4fb6585ea98643089032b", "signature_position": [260, 260], "body_position": [261, 262], "signature": "def parse_version(s: str) -> tuple[int, ...]:", "ground_truth": "def parse_version(s: str) -> tuple[int, ...]:\n    \"\"\"poor man's version comparison\"\"\"\n    return tuple(int(p) for p in s.split('.'))", "requirement": {"Functionality": "poor man's version comparison", "Arguments": ""}}
{"namespace": "pre_commit.parse_shebang.normalize_cmd", "type": "function", "project_path": "pre-commit/pre-commit", "completion_path": "pre_commit/parse_shebang.py", "coder_eval_id": "62e4fb4d85ea9864308902e7", "signature_position": [65, 65], "body_position": [66, 81], "signature": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:", "ground_truth": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    \"\"\"Fixes for the following issues on windows\n    - https://bugs.python.org/issue8557\n    - windows does not parse shebangs\n\n    This function also makes deep-path shebangs work just fine\n    \"\"\"\n    # Use PATH to determine the executable\n    exe = normexe(cmd[0])\n\n    # Figure out the shebang from the resulting command\n    cmd = parse_filename(exe) + (exe,) + cmd[1:]\n\n    # This could have given us back another bare executable\n    exe = normexe(cmd[0])\n\n    return (exe,) + cmd[1:]", "requirement": {"Functionality": "Fixes for the following issues on windows\n- https://bugs.python.org/issue8557\n- windows does not parse shebangs\n\nThis function also makes deep-path shebangs work just fine", "Arguments": ""}}
{"namespace": "cachetools.decorators.cached", "type": "function", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/decorators.py", "coder_eval_id": "62b8d27a48ba5a41d1c3f4c6", "signature_position": [6, 6], "body_position": [7, 44], "signature": "def cached(cache, key=hashkey, lock=None):", "ground_truth": "def cached(cache, key=hashkey, lock=None):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    results in a cache.\n\n    \"\"\"\n    def decorator(func):\n        if cache is None:\n            def wrapper(*args, **kwargs):\n                return func(*args, **kwargs)\n        elif lock is None:\n            def wrapper(*args, **kwargs):\n                k = key(*args, **kwargs)\n                try:\n                    return cache[k]\n                except KeyError:\n                    pass  # key not found\n                v = func(*args, **kwargs)\n                try:\n                    cache[k] = v\n                except ValueError:\n                    pass  # value too large\n                return v\n        else:\n            def wrapper(*args, **kwargs):\n                k = key(*args, **kwargs)\n                try:\n                    with lock:\n                        return cache[k]\n                except KeyError:\n                    pass  # key not found\n                v = func(*args, **kwargs)\n                # in case of a race, prefer the item already in the cache\n                try:\n                    with lock:\n                        return cache.setdefault(k, v)\n                except ValueError:\n                    return v  # value too large\n        return functools.update_wrapper(wrapper, func)\n    return decorator", "requirement": {"Functionality": "Decorator to wrap a function with a memoizing callable that saves\nresults in a cache.", "Arguments": ""}}
{"namespace": "cachetools.func.ttl_cache", "type": "function", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/func.py", "coder_eval_id": "62b8d24048ba5a41d1c3f49f", "signature_position": [166, 166], "body_position": [167, 176], "signature": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):", "ground_truth": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Least Recently Used (LRU)\n    algorithm with a per-item time-to-live (TTL) value.\n    \"\"\"\n    if maxsize is None:\n        return _cache(_UnboundTTLCache(ttl, timer), typed)\n    elif callable(maxsize):\n        return _cache(TTLCache(128, ttl, timer), typed)(maxsize)\n    else:\n        return _cache(TTLCache(maxsize, ttl, timer), typed)", "requirement": {"Functionality": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm with a per-item time-to-live (TTL) value.", "Arguments": ""}}
{"namespace": "cachetools.func.mru_cache", "type": "function", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/func.py", "coder_eval_id": "62b8d23b48ba5a41d1c3f49a", "signature_position": [139, 139], "body_position": [140, 149], "signature": "def mru_cache(maxsize=128, typed=False):", "ground_truth": "def mru_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Most Recently Used (MRU)\n    algorithm.\n    \"\"\"\n    if maxsize is None:\n        return _cache(_UnboundCache(), typed)\n    elif callable(maxsize):\n        return _cache(MRUCache(128), typed)(maxsize)\n    else:\n        return _cache(MRUCache(maxsize), typed)", "requirement": {"Functionality": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Most Recently Used (MRU)\nalgorithm.", "Arguments": ""}}
{"namespace": "cachetools.func.lru_cache", "type": "function", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/func.py", "coder_eval_id": "62b8d23948ba5a41d1c3f498", "signature_position": [125, 125], "body_position": [126, 136], "signature": "def lru_cache(maxsize=128, typed=False):", "ground_truth": "def lru_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Least Recently Used (LRU)\n    algorithm.\n\n    \"\"\"\n    if maxsize is None:\n        return _cache(_UnboundCache(), typed)\n    elif callable(maxsize):\n        return _cache(LRUCache(128), typed)(maxsize)\n    else:\n        return _cache(LRUCache(maxsize), typed)", "requirement": {"Functionality": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm.", "Arguments": ""}}
{"namespace": "cachetools.func.lfu_cache", "type": "function", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/func.py", "coder_eval_id": "62b8d23748ba5a41d1c3f496", "signature_position": [111, 111], "body_position": [112, 122], "signature": "def lfu_cache(maxsize=128, typed=False):", "ground_truth": "def lfu_cache(maxsize=128, typed=False):\n    \"\"\"Decorator to wrap a function with a memoizing callable that saves\n    up to `maxsize` results based on a Least Frequently Used (LFU)\n    algorithm.\n\n    \"\"\"\n    if maxsize is None:\n        return _cache(_UnboundCache(), typed)\n    elif callable(maxsize):\n        return _cache(LFUCache(128), typed)(maxsize)\n    else:\n        return _cache(LFUCache(maxsize), typed)", "requirement": {"Functionality": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Frequently Used (LFU)\nalgorithm.", "Arguments": ""}}
{"namespace": "cachetools.fifo.popitem", "type": "class", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/fifo.py", "coder_eval_id": "62b8d22f48ba5a41d1c3f488", "signature_position": [24, 24], "body_position": [25, 31], "signature": "def popitem(self):", "ground_truth": "    def popitem(self):\n        \"\"\"Remove and return the `(key, value)` pair first inserted.\"\"\"\n        try:\n            key = next(iter(self.__order))\n        except StopIteration:\n            raise KeyError('%s is empty' % type(self).__name__) from None\n        else:\n            return (key, self.pop(key))", "requirement": {"Functionality": "Remove and return the `(key, value)` pair first inserted.", "Arguments": ""}}
{"namespace": "cachetools.cache.setdefault", "type": "class", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/cache.py", "coder_eval_id": "62b8d22a48ba5a41d1c3f47e", "signature_position": [97, 97], "body_position": [98, 102], "signature": "def setdefault(self, key, default=None):", "ground_truth": "    def setdefault(self, key, default=None):\n        if key in self:\n            value = self[key]\n        else:\n            self[key] = value = default\n        return value", "requirement": {"Functionality": "D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D", "Arguments": ""}}
{"namespace": "cachetools.cache.get", "type": "class", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/cache.py", "coder_eval_id": "62b8d22948ba5a41d1c3f47c", "signature_position": [81, 81], "body_position": [82, 85], "signature": "def get(self, key, default=None):", "ground_truth": "    def get(self, key, default=None):\n        if key in self:\n            return self[key]\n        else:\n            return default", "requirement": {"Functionality": "D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.", "Arguments": ""}}
{"namespace": "cachetools.decorators.cachedmethod", "type": "function", "project_path": "pexip/os-python-cachetools", "completion_path": "cachetools/decorators.py", "coder_eval_id": "62b8d22548ba5a41d1c3f472", "signature_position": [47, 47], "body_position": [48, 88], "signature": "def cachedmethod(cache, key=hashkey, lock=None):", "ground_truth": "def cachedmethod(cache, key=hashkey, lock=None):\n    \"\"\"Decorator to wrap a class or instance method with a memoizing\n    callable that saves results in a cache.\n\n    \"\"\"\n    def decorator(method):\n        if lock is None:\n            def wrapper(self, *args, **kwargs):\n                c = cache(self)\n                if c is None:\n                    return method(self, *args, **kwargs)\n                k = key(*args, **kwargs)\n                try:\n                    return c[k]\n                except KeyError:\n                    pass  # key not found\n                v = method(self, *args, **kwargs)\n                try:\n                    c[k] = v\n                except ValueError:\n                    pass  # value too large\n                return v\n        else:\n            def wrapper(self, *args, **kwargs):\n                c = cache(self)\n                if c is None:\n                    return method(self, *args, **kwargs)\n                k = key(*args, **kwargs)\n                try:\n                    with lock(self):\n                        return c[k]\n                except KeyError:\n                    pass  # key not found\n                v = method(self, *args, **kwargs)\n                # in case of a race, prefer the item already in the cache\n                try:\n                    with lock(self):\n                        return c.setdefault(k, v)\n                except ValueError:\n                    return v  # value too large\n        return functools.update_wrapper(wrapper, method)\n    return decorator", "requirement": {"Functionality": "Decorator to wrap a class or instance method with a memoizing\ncallable that saves results in a cache.", "Arguments": ""}}
{"namespace": "pysolbase.SolBase.extostr", "type": "class", "project_path": "champax/pysolbase", "completion_path": "pysolbase/SolBase.py", "coder_eval_id": "62b8c517e0d34b282c18122e", "signature_position": [286, 286], "body_position": [287, 381], "signature": "@classmethod\ndef extostr(cls, e, max_level=30, max_path_level=5):", "ground_truth": "    @classmethod\n    def extostr(cls, e, max_level=30, max_path_level=5):\n        \"\"\"\n        Format an exception.\n        :param e: Any exception instance.\n        :type e: Exception\n        :param max_level: Maximum call stack level (default 30)\n        :type max_level: int\n        :param max_path_level: Maximum path level (default 5)\n        :type max_path_level: int\n        :return The exception readable string\n        :rtype str\n        \"\"\"\n\n        # Go\n        list_frame = None\n        try:\n            out_buffer = \"\"\n\n            # Class type\n            out_buffer += \"e.cls:[{0}]\".format(e.__class__.__name__)\n\n            # To string\n            try:\n                ex_buf = str(e)\n            except UnicodeEncodeError:\n                ex_buf = repr(str(e))\n            except Exception as e:\n                logger.warning(\"Exception, e=%s\", e)\n                raise\n            out_buffer += \", e.bytes:[{0}]\".format(ex_buf)\n\n            # Traceback\n            si = sys.exc_info()\n\n            # Raw frame\n            # tuple : (file, lineno, method, code)\n            raw_frame = traceback.extract_tb(si[2])\n            raw_frame.reverse()\n\n            # Go to last tb_next\n            last_tb_next = None\n            cur_tb = si[2]\n            while cur_tb:\n                last_tb_next = cur_tb\n                cur_tb = cur_tb.tb_next\n\n            # Skip frame up to current raw frame count\n            list_frame = list()\n            cur_count = -1\n            skip_count = len(raw_frame)\n            if last_tb_next:\n                cur_frame = last_tb_next.tb_frame\n            else:\n                cur_frame = None\n            while cur_frame:\n                cur_count += 1\n                if cur_count < skip_count:\n                    cur_frame = cur_frame.f_back\n                else:\n                    # Need : tuple : (file, lineno, method, code)\n                    raw_frame.append((cur_frame.f_code.co_filename, cur_frame.f_lineno, cur_frame.f_code.co_name, \"\"))\n                    cur_frame = cur_frame.f_back\n\n            # Build it\n            cur_idx = 0\n            out_buffer += \", e.cs=[\"\n            for tu in raw_frame:\n                line = tu[1]\n                cur_file = tu[0]\n                method = tu[2]\n\n                # Handle max path level\n                ar_token = cur_file.rsplit(os.sep, max_path_level)\n                if len(ar_token) > max_path_level:\n                    # Remove head\n                    ar_token.pop(0)\n                    # Join\n                    cur_file = \"...\" + os.sep.join(ar_token)\n\n                # Format\n                out_buffer += \"in:{0}#{1}@{2} \".format(method, cur_file, line)\n\n                # Loop\n                cur_idx += 1\n                if cur_idx >= max_level:\n                    out_buffer += \"...\"\n                    break\n\n            # Close\n            out_buffer += \"]\"\n\n            # Ok\n            return out_buffer\n        finally:\n            if list_frame:\n                del list_frame", "requirement": {"Functionality": "Format an exception.\n:param e: Any exception instance.\n:type e: Exception\n:param max_level: Maximum call stack level (default 30)\n:type max_level: int\n:param max_path_level: Maximum path level (default 5)\n:type max_path_level: int\n:return The exception readable string\n:rtype str", "Arguments": ""}}
{"namespace": "pysolbase.FileUtility.append_text_to_file", "type": "class", "project_path": "champax/pysolbase", "completion_path": "pysolbase/FileUtility.py", "coder_eval_id": "62b8bbbfe0d34b282c181210", "signature_position": [233, 233], "body_position": [234, 271], "signature": "@staticmethod\ndef append_text_to_file(file_name, text_buffer, encoding, overwrite=False):", "ground_truth": "    @staticmethod\n    def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n        \"\"\"\n        Write to the specified filename, the provided binary buffer\n        Create the file if required.\n        :param file_name:  File name.\n        :type file_name: str\n        :param text_buffer: Text buffer to write.\n        :type text_buffer: str\n        :param encoding: The encoding to use.\n        :type encoding: str\n        :param overwrite: If true, file is overwritten.\n        :type overwrite: bool\n        :return: The number of bytes written or lt 0 if error.\n        :rtype int\n        \"\"\"\n\n        # Go\n        rd = None\n        try:\n            # Open (text : open return a io.BufferedReader)\n            if not overwrite:\n                rd = codecs.open(file_name, \"a+\", encoding, \"strict\", -1)\n            else:\n                rd = codecs.open(file_name, \"w\", encoding, \"strict\", -1)\n\n            # Read everything\n            # CAUTION : 2.7 return None :(\n            return rd.write(text_buffer)\n        except IOError as e:\n            # Exception...\n            logger.warning(\"append_text_to_file : IOError, ex=%s\", SolBase.extostr(e))\n            return -1\n        except Exception as e:\n            logger.warning(\"append_text_to_file : Exception, ex=%s\", SolBase.extostr(e))\n            return -1\n        finally:\n            # Close if not None...\n            if rd:\n                rd.close()", "requirement": {"Functionality": "Write to the specified filename, the provided binary buffer\nCreate the file if required.\n:param file_name:  File name.\n:type file_name: str\n:param text_buffer: Text buffer to write.\n:type text_buffer: str\n:param encoding: The encoding to use.\n:type encoding: str\n:param overwrite: If true, file is overwritten.\n:type overwrite: bool\n:return: The number of bytes written or lt 0 if error.\n:rtype int", "Arguments": ""}}
{"namespace": "pysolbase.FileUtility.file_to_textbuffer", "type": "class", "project_path": "champax/pysolbase", "completion_path": "pysolbase/FileUtility.py", "coder_eval_id": "62b8bbbfe0d34b282c18120f", "signature_position": [162, 162], "body_position": [163, 197], "signature": "@staticmethod\ndef file_to_textbuffer(file_name, encoding):", "ground_truth": "    @staticmethod\n    def file_to_textbuffer(file_name, encoding):\n        \"\"\"\n        Load a file toward a text buffer (UTF-8), using the specify encoding while reading.\n        CAUTION : This will read the whole file IN MEMORY.\n        :param file_name: File name.\n        :type file_name: str\n        :param encoding: Encoding to use.\n        :type encoding: str\n        :return: A text buffer or None in case of error.\n        :rtype str\n        \"\"\"\n\n        # Check\n        if not FileUtility.is_file_exist(file_name):\n            logger.warning(\"file_to_textbuffer : file_name not exist, file_name=%s\", file_name)\n            return None\n\n        # Go\n        rd = None\n        try:\n            # Open (text : open return a io.BufferedReader)\n            rd = codecs.open(file_name, \"r\", encoding, \"strict\", -1)\n\n            # Read everything\n            return rd.read()\n        except IOError as e:\n            # Exception...\n            logger.warning(\"file_to_binary : IOError, ex=%s\", SolBase.extostr(e))\n            return None\n        except Exception as e:\n            logger.warning(\"file_to_binary : Exception, ex=%s\", SolBase.extostr(e))\n            return None\n        finally:\n            # Close if not None...\n            if rd:\n                rd.close()", "requirement": {"Functionality": "Load a file toward a text buffer (UTF-8), using the specify encoding while reading.\nCAUTION : This will read the whole file IN MEMORY.\n:param file_name: File name.\n:type file_name: str\n:param encoding: Encoding to use.\n:type encoding: str\n:return: A text buffer or None in case of error.\n:rtype str", "Arguments": ""}}
{"namespace": "pysolbase.FileUtility.is_file_exist", "type": "class", "project_path": "champax/pysolbase", "completion_path": "pysolbase/FileUtility.py", "coder_eval_id": "62b8bbbce0d34b282c18120d", "signature_position": [61, 61], "body_position": [62, 79], "signature": "@staticmethod\ndef is_file_exist(file_name):", "ground_truth": "    @staticmethod\n    def is_file_exist(file_name):\n        \"\"\"\n        Check if file name exist.\n        :param file_name: File name.\n        :type file_name: str\n        :return: Return true (exist), false (do not exist, or invalid file name)\n        :rtype bool\n        \"\"\"\n\n        # Check\n        if file_name is None:\n            logger.warning(\"is_file_exist : file_name is None\")\n            return False\n        elif not isinstance(file_name, str):\n            logger.warning(\"is_file_exist : file_name not a text_type, className=%s\", SolBase.get_classname(file_name))\n            return False\n\n        # Go\n        return os.path.isfile(file_name)", "requirement": {"Functionality": "Check if file name exist.\n:param file_name: File name.\n:type file_name: str\n:return: Return true (exist), false (do not exist, or invalid file name)\n:rtype bool", "Arguments": ""}}
{"namespace": "pysolbase.SolBase._reset_logging", "type": "class", "project_path": "champax/pysolbase", "completion_path": "pysolbase/SolBase.py", "coder_eval_id": "62b8b99de0d34b282c1811f8", "signature_position": [597, 597], "body_position": [598, 626], "signature": "@classmethod\ndef _reset_logging(cls):", "ground_truth": "    @classmethod\n    def _reset_logging(cls):\n        \"\"\"\n        Reset\n        \"\"\"\n\n        # Found no way to fully reset the logging stuff while running\n        # We reset root and all loggers to INFO, and kick handlers\n\n        # Initialize\n        root = logging.getLogger()\n        root.setLevel(logging.getLevelName(\"INFO\"))\n        for h in root.handlers:\n            # noinspection PyBroadException\n            try:\n                h.close()\n            except:\n                pass\n        root.handlers = []\n\n        # Browse all loggers and set\n        for name in logging.root.manager.loggerDict:\n            cur_logger = logging.getLogger(name)\n            cur_logger.setLevel(logging.getLevelName(\"INFO\"))\n            for h in cur_logger.handlers:\n                # noinspection PyBroadException\n                try:\n                    h.close()\n                except:\n                    pass\n            cur_logger.handlers = []", "requirement": {"Functionality": "Reset", "Arguments": ""}}
{"namespace": "src.zope.interface.tests.test_declarations._getTargetClass", "type": "class", "project_path": "pexip/os-zope", "completion_path": "src/zope/interface/tests/test_declarations.py", "coder_eval_id": "62b8b59feb7e40a82d2d1291", "signature_position": [1893, 1893], "body_position": [1894, 1895], "signature": "def _getTargetClass(self):", "ground_truth": "    def _getTargetClass(self):\n        from zope.interface.declarations import getObjectSpecification\n        return getObjectSpecification", "requirement": {"Functionality": "Define this to return the implementation in use,\nwithout the 'Py' or 'Fallback' suffix.", "Arguments": ""}}
